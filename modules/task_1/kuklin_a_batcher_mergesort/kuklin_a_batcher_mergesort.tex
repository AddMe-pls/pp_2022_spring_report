\documentclass{report}

\usepackage[warn]{mathtext}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{luainputenc}
\usepackage[english, russian]{babel}
\usepackage[pdftex]{hyperref}
\usepackage{tempora}
\usepackage[12pt]{extsizes}
\usepackage{listings}
\usepackage{color}
\usepackage{geometry}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{indentfirst}
\usepackage{amsmath}

\geometry{a4paper,top=2cm,bottom=2cm,left=2.5cm,right=1.5cm}
\setlength{\parskip}{0.5cm}
\setlist{nolistsep, itemsep=0.3cm,parsep=0pt}

\usepackage{listings}
\lstset{language=C++,
        basicstyle=\footnotesize,
		keywordstyle=\color{blue}\ttfamily,
		stringstyle=\color{red}\ttfamily,
		commentstyle=\color{green}\ttfamily,
		morecomment=[l][\color{red}]{\#}, 
		tabsize=4,
		breaklines=true,
  		breakatwhitespace=true,
  		title=\lstname,       
}

\makeatletter
\renewcommand\@biblabel[1]{#1.\hfil}
\makeatother

\begin{document}

\begin{titlepage}

\begin{center}
Министерство науки и высшего образования Российской Федерации
\end{center}

\begin{center}
Федеральное государственное автономное образовательное учреждение высшего образования \\
Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского
\end{center}

\begin{center}
Институт информационных технологий, математики и механики
\end{center}

\vspace{4em}

\begin{center}
\textbf{\LargeОтчет по лабораторной работе} \\
\end{center}
\begin{center}
\textbf{\Large«Поразрядная сортировка для вещественных чисел (тип double) с четно-нечетным слиянием Бэтчера»} \\
\end{center}

\vspace{4em}

\newbox{\lbox}
\savebox{\lbox}{\hbox{text}}
\newlength{\maxl}
\setlength{\maxl}{\wd\lbox}
\hfill\parbox{7cm}{
\hspace*{5cm}\hspace*{-5cm}\textbf{Выполнил:} \\ студент группы 381906-3 \\ Куклин А. Е.\\
\\
\hspace*{5cm}\hspace*{-5cm}\textbf{Проверил:}\\ доцент кафедры МОСТ, \\ кандидат технических наук \\ Сысоев А. В.\\
}
\vspace{\fill}

\begin{center} Нижний Новгород \\ 2022 \end{center}

\end{titlepage}

\setcounter{page}{2}

% Содержание
\tableofcontents
\newpage

% Введение
\section*{Введение}
\addcontentsline{toc}{section}{Введение}
\par Алгоритм сортировки — это алгоритм для упорядочивания элементов в массиве. В случае, когда элемент в массиве имеет несколько полей, поле, служащее критерием порядка, называется ключом сортировки. На практике в качестве ключа часто выступает число, а в остальных полях хранятся какие-либо данные, никак не влияющие на работу алгоритма.
\par Алгоритм поразрядной сортировки предназначен для сортировки целых чисел, записанных цифрами. Но так как в памяти компьютеров любая информация записывается целыми числами, алгоритм пригоден для сортировки любых объектов, запись которых можно поделить на «разряды», содержащие сравнимые значения. Например, так сортировать можно не только числа, записанные в виде набора цифр, но и строки, являющиеся набором символов, и вообще произвольные значения в памяти, представленные в виде набора байт.
\par Сортировка большого количества данных может занимать достаточно много времени. Подобные алгоритмы можно ускорить за счет исполнения программы на нескольких потоках. Это позволит получить значительное уменьшение времени работы алгоритма. 
\newpage

% Постановка задачи
\section*{Постановка задачи}
\addcontentsline{toc}{section}{Постановка задачи}
\par Необходимо реализовать программу, производящую поразрядную сортировку для вещественных чисел. В программе должны быть реализованы последовательный и параллельный алгоритм решения. Для реализации параллельной части программы необходимо использовать технологии OpenMP, TBB, std::thread.
\par Также необходимо проверить корректность работы программы. Для этого нужно задействовать библиотеку модульного тестирования Google Test. При проверке корректности работы программы необходимо убедиться, что параллельная версия работает быстрее последовательной.
\par По окончании работы нужно сделать выводы о том, насколько эффективно распараллеливание заданного алгоритма и сравнить технологии распараллеливания, выяснив, какие из них лучше подходят для данной задачи. Выводы должны строиться на основании полученных данных о времени работы программы.
\newpage

% Описание алгоритма
\section*{Описание алгоритма}
\addcontentsline{toc}{section}{Описание алгоритма}
\par Поразрядная сортировка для вещественных чисел осуществляется следующим образом:
\par Дан исходный массив source из n элементов. Создается массив массивов count, размер которого равен количеству разрядов сортируемого элемента (в данном случен это 256, т.к. беззнаковый байт может принимать значения от 0 до 255). Производится сортировка по младшему разряду (по первому байту). Присвоить count[$i$], где $i = \overline{0, 255}$, количество элементов из массива source, первый байт которых равен $i$ следующим образом: count[$i$] инициализируется нулями, и за один проход по исходному массиву source для каждого числа инкрементируется элемент count с соответствующим номером. Присвоить count[$i$] значение, равное сумме всех элементов до данного и произвести окончательную расстановку элементов в результирующий массив.
\par Повторить алгоритм для оставшихся разрядов, кроме старшего (последнего байта). Последний байт в первом бите содержит информацию о знаке числа: 0 - число положительное, 1 - отрицательное. Исходя из этого, необходимо произвести расстановку по массиву count в следующем порядке: пройти от count[255], соответствующего наименьшему отрицательному числу, до count[128], соответствующего наибольшему отрицательному. Далее, от count[0], соответствующего наименьшему положительному числу, до count[127], соответствующего наибольшему положительному. Результатом исполненного алгоритма будет отсортированный массив.
\par Четно-нечетное слияние Бэтчера двух массивов производится следующим образом: производится слияние четных элементов из двух исходных массивов, эти элементы в отсортированном порядке записываются на четные позиции результирующего массива. Далее, производится слияние нечетных элементов, они, в отсортированном порядке, записываются на нечетные позиции результирующего массива. В полученном массиве производится проход по всем элементам, если соседние расположены в неправильном порядке, их позиции меняются местами.
\newpage

% Описание схемы распараллеливания
\section*{Описание схемы распараллеливания}
\addcontentsline{toc}{section}{Описание схемы распараллеливания}
\par Данный алгоритм распараллеливается следующим образом: исходный массив разделяется на отдельные массивы, число которых равно числу потоков, участвующих в программе. Количество элементов таких массивов будет равное $\lfloor\frac{Size}{thread\_number}\rfloor$, где $Size$ - число элементов исходного массива, $thread\_number$ - количество потоков, доступных программе. В каждом полученном массиве производится поразрядная сортировка потоком, номер которого соответствует номеру массива. После выполнения сортировки всеми потоками, производится четно-нечетное слияние Бэтчера всех массивов в один, получая на выходе отсортированный массив.
\par Для реализации данного алгоритма, в OpenMP в директиву \#pragma omp parallel необходимо передать параметр num\_threads с числом потоков, используемых программой. Таким образом, можно выполнить параллельную сортировку отдельных частей массива.
\par В технологии TBB используется tbb::parallel\_for, в который передаются 2 параметра: итерационное пространство и функтор. Итерационное пространство можно задать таким образом, чтобы каждому потоку для сортировки досталась своя часть исходного массива. В функторе, с помощью лямбда-выражения выполнить сортировку части итерационного пространства, переданной очередному потоку.
\par Для использования std::thread необходимо каждый поток, доступный программе, проинициализировать. В данном случае, в конструктор std::thread передается функция по сортировке массива и сам массив, который нужно отсортировать. Так, на каждый поток передастся определенная часть исходного массива, которая будет отсортирована.
\newpage

% Описание программной реализации
\section*{Описание программной реализации}
\addcontentsline{toc}{section}{Описание программной реализации}
\par Программа включает в себя 3 файла: main.cpp, batcher\_mergesort.cpp - исходные файлы, batcher\_mergesort.h - заголовочный файл.
\par В заголовочном файле объявлены функции программы, в исходном файле main.cpp реализованы тесты для проверки корректности программы и замера времени и main программы, в файле batcher\_mergesort.cpp расположена реализация вышеупомянутых функций. 
\par Реализованные функции:
\begin{lstlisting}
    std::vector<double> getRandVec(size_t vec_size, double lower_bound, double upper_bound);
    void genDigitCounters(std::vector<double>* source_vec, size_t elem_num);
    void radixPass(std::vector<double>* source_vec, const std::vector<std::vector<double>>& digitCounters);
    void floatRadixSort(std::vector<double>* source_vec);
    void evenSplitter(std::vector<double>* res_vec, const std::vector<double>& first_vec, const std::vector<double>& second_vec);
    void oddSplitter(std::vector<double>* res_vec, const std::vector<double>& first_vec, const std::vector<double>& second_vec);
    void batcherComparator(std::vector<double>* res_vec);
    std::vector<double> batcherMerge(const std::vector<double>& first_vec, const std::vector<double>& second_vec);
    void floatRadixSortParallel(std::vector<double>* source_vec);
\end{lstlisting}
\par Функция getRandVec предназначена для создания вектора значений double заданного размера, в заданном диапазоне. Функции genDigitCounters и radixPass - вспомогательные функции для сортировки. genDigitCounters создает вектор счетчиков, позволяющих вставить элемент на нужное место в векторе, в зависимости от значений байта числа. radixPass производит сортировку по последнему байту. Функция floatRadixSort производит поразрядную сортировку переданного вектора.
\par evenSplitter, oddSplitter, batcherComparator - вспомогательные функции, которые используются в batcherMerge. На вход функции evenSplitter подаются два вектора, четные элементы которых необходимо слить, и результирующий вектор, на четные позиции которого будут присваиваться упорядоченные элементы. Аналогичным образом для нечетных элементов действует функция oddSplitter. batcherComparator сравнивает соседние элементы, поступившего на вход вектора, если порядок нарушен - элементы меняются местами. Функция batcherMerge производит слияние двух векторов.
\par Функция floatRadixSortParallel производит параллельную сортировку исходного вектора. Реализация этой функции различна, в зависимости от используемой технологии.
\par Файл main.cpp содержит набор unit-тестов, реализованных с помощью библиотеки Google Test.
\newpage

% Подтверждение корректности
\section*{Подтверждение корректности}
\addcontentsline{toc}{section}{Подтверждение корректности}
\par Корректность работы программы была проверена с помощью инструмента модульного тестирования Google Test. В тестах проверяется упорядоченность массива, полученного после завершения работы функций сортировки. Также, реализованы тесты, в которых сравниваются массивы, полученные в результате выполнения последовательной и параллельной версий сортировки.
\par Чтобы убедиться в том, что параллельный алгоритм работает корректно, необходимо проверить его скорость работы. Для этого были реализованы тесты, сравнивающие время выполнения последовательной и параллельной версий.
\newpage

% Результаты экспериментов
\section*{Результаты экспериментов}
\addcontentsline{toc}{section}{Результаты экспериментов}
Скорость выполнения программы во многом зависит от архитектуры ЭВМ. Был использован ПК со следующими характеристиками:
\begin{itemize}
\item Процессор: Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz, 3201 МГц, ядер: 4, логических процессоров: 4;
\item Оперативная память (RAM): 8,00 ГБ;
\item Операционная система: Майкрософт Windows 10 Pro
\end{itemize}
\par Эксперименты проведены на разных размерах сортируемого массива - n, представлено время - time (в секундах) работы последовательного алгоритма (sequential), время работы параллельного алгоритма с использованием технологии OpenMP, с использованием TBB, с использованием std::thread и ускорение (boost) для вышеперечисленных параллельных версий, которое считается по формуле: boost = $\frac{time\_seq}{time\_paral}$.

\par В следующих таблицах представлены результаты:.

\begin{table}[!h]
\centering
\begin{tabular}{| p{3cm} | p{3cm} | p{2cm} |}
\hline
version & time (s) & boost  \\[5pt]
\hline
sequential        & 6.471      & -  \\
OpenMP         & 3.361     & 1.925   \\
TBB        & 3.164      & 2.045   \\
std::thread        & 4.216     & 1.534   \\
\hline
\end{tabular}
\caption{n = $50 * 10^6$}
\end{table}

\begin{table}[!h]
\centering
\begin{tabular}{| p{3cm} | p{3cm} | p{2cm} |}
\hline
version & time (s) & boost  \\[5pt]
\hline
sequential        & 15.976      & -  \\
OpenMP         & 6.040     & 2.645   \\
TBB        & 5.469      & 2.921   \\
std::thread        & 7.174     & 2.226   \\
\hline
\end{tabular}
\caption{n = $100 * 10^6$}
\end{table}

\newpage

% Выводы из результатов экспериментов
\section*{Выводы из результатов экспериментов}
\addcontentsline{toc}{section}{Выводы из результатов экспериментов}
\par Исходя из приведенных результатов, можно сказать, что в общем случае увеличение количества данных приводит к большему ускорению работы параллельной программы относительно последовательной. Во всех произведенных экспериментах самой быстрой версией оказалась программа, исплользующая технологию TBB. Это связано с динамическим распределением работы на потоки, используемым в данной библиотеке. Самой медленной из параллельных конфигураций оказалась программа, реализовання с помощью std::thread. Эта технология подразумевает явную инициализацию потоков, исполняющих программу. В связи с этим появляются дополнительные расходы времени процессора, что делает реализацию алгоритма с использованием std::thread медленнее других параллельных версий.

\newpage

% Заключение
\section*{Заключение}
\addcontentsline{toc}{section}{Заключение}
\par В ходе данной задачи были реализованы последовательный алгоритм поразрядной сортировки, а также параллельные реализации с использованием технологий OpenMP, TBB и std::thread, что позволило лучше понять принципы работы параллельного программирования, работы с потоками и освоить вышеупомянутые технологии. В результате экспериментов выяснилось, что распараллеливание подобных алгоритмов зачастую сильно ускоряет работу программы, что говорит о важности и актуальности проделанной работы.
\newpage

% Литература
\section*{Литература}
\addcontentsline{toc}{section}{Литература}
\begin{enumerate}
\item Wikipedia - электронный ресурс. URL: \url{https://en.wikipedia.org/wiki/Radix_sort} (дата обращения: 28.05.2022)
\item Wikipedia - электронный ресурс. URL: \url{https://en.wikipedia.org/wiki/Bitonic_sorter} (дата обращения: 28.05.2022)
\item Reference Guides OpenMP - электронный ресурс. URL: \url{https://www.openmp.org} (дата обращения: 28.05.2022)
\item Intel oneAPI Threading Building Blocks - электронный ресурс. URL: \url{https://www.intel.com/content/www/us/en/developer/tools/oneapi/onetbb.html} (дата обращения: \break 28.05.2022)
\item cppreference - электронный ресурс. URL: \url{https://en.cppreference.com/w/cpp/thread/thread} (дата обращения: 28.05.2022)
\end{enumerate} 
\newpage

% Приложение
\section*{Приложение}
\addcontentsline{toc}{section}{Приложение}
\textbf{Sequential version}
\par batcher\_mergesort.h
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#ifndef MODULES_TASK_1_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
#define MODULES_TASK_1_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_

#include <vector>

using vector_d = std::vector<double>;

std::vector<double> getRandVec(size_t vec_size, double lower_bound,
                               double upper_bound);
std::vector<vector_d> genDigitCounters(vector_d* source_vec, size_t elem_num);
void radixPass(vector_d* source_vec, const std::vector<vector_d>& digitCounters);
void floatRadixSort(vector_d* source_vec);
void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec);
void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec);
void batcherComparator(vector_d* res_vec);
vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec);

#endif  // MODULES_TASK_1_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
\end{lstlisting}
\par batcher\_mergesort.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include "../../../modules/task_1/kuklin_a_batcher_mergesort/batcher_mergesort.h"
#include <algorithm>
#include <vector>
#include <random>

using vector_d = std::vector<double>;
constexpr size_t bv = 256;

vector_d getRandVec(size_t vec_size, double lower_bound, double upper_bound) {
  vector_d vec(vec_size);
  std::uniform_real_distribution<double> distribution(lower_bound, upper_bound);
  std::random_device device;
  std::mt19937 rnd(device());

  for (size_t i = 0; i < vec_size; ++i) vec[i] = distribution(rnd);

  return vec;
}

std::vector<vector_d> genDigitCounters(vector_d* source_vec, size_t elem_num) {
  std::vector<vector_d> digitCounters(256);
  int index_sv = 0;
  int curr_byte = 0;

  for (size_t byte_num = 0; byte_num < sizeof(double); ++byte_num) {
    for (size_t elem_ind = 0; elem_ind < elem_num; ++elem_ind) {
      curr_byte = static_cast<int>(
          *((unsigned char*)&(*source_vec)[elem_ind] + byte_num));
      digitCounters[curr_byte].push_back((*source_vec)[elem_ind]);
    }

  size_t count_size = 0;
    for (size_t i = 0; i < bv; ++i) {
      if (!digitCounters.empty()) {
        count_size = digitCounters[i].size();
        for (size_t j = 0; j < count_size; ++j) {
          (*source_vec)[index_sv++] = digitCounters[i][j];
        }
        digitCounters[i].clear();
      }
    }
    index_sv = 0;
  }

  return digitCounters;
}

void radixPass(vector_d* source_vec, const std::vector<vector_d>& digitCounters) {
  size_t index_v = 0;
  size_t count_size = 0;

  for (size_t i = bv - 1; i >= bv / 2; --i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t k = count_size - 1; k >= 1; --k) {
        (*source_vec)[index_v++] = digitCounters[i][k];
      }
      (*source_vec)[index_v++] = digitCounters[i][0];
    }
  }

  for (size_t i = 0; i < bv / 2; ++i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t j = 0; j < count_size; ++j) {
        (*source_vec)[index_v++] = digitCounters[i][j];
      }
    }
  }
}

void floatRadixSort(vector_d* source_vec) {
  size_t elem_num = source_vec->size();

  auto digitCounters = genDigitCounters(source_vec, elem_num);

  int count_index = 0;
  for (size_t i = 0; i < elem_num; ++i) {
    count_index = static_cast<int>(*((unsigned char*)&(*source_vec)[i] + 7));
    digitCounters[count_index].push_back((*source_vec)[i]);
  }

  radixPass(source_vec, digitCounters);
}

void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec) {
  size_t index_a = 0;
  size_t index_b = 0;
  size_t i = 0;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }
}

void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec) {
  size_t index_a = 1;
  size_t index_b = 1;
  size_t i = 1;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }

  if (first_size % 2 == 1 && second_size % 2 == 1) {
    (*res_vec)[first_size + second_size - 1] =
        std::max(first_vec[first_size - 1], second_vec[second_size - 1]);
  }
}

void batcherComparator(vector_d* res_vec) {
  auto res_size = res_vec->size();

  for (size_t i = 1; i < res_size; ++i) {
    if ((*res_vec)[i] < (*res_vec)[i - 1])
      std::swap((*res_vec)[i], (*res_vec)[i - 1]);
  }
}

vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec) {
  auto first_size = first_vec.size();
  auto second_size = second_vec.size();
  vector_d res_vec(first_size + second_size);

  evenSplitter(&res_vec, first_vec, second_vec);
  oddSplitter(&res_vec, first_vec, second_vec);
  batcherComparator(&res_vec);

  return res_vec;
}
\end{lstlisting}
\par main.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include <gtest/gtest.h>
#include "./batcher_mergesort.h"

TEST(kuklin_a_betcher_mergesort, genRandVec) {
  ASSERT_NO_THROW(getRandVec(10, -100., 100.));
}

TEST(kuklin_a_betcher_mergesort, can_sort_positive_nubm) {
  auto vec = getRandVec(10, 10., 30.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_negative_nubm) {
  auto vec = getRandVec(10, -30., -20.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_rand_nubm) {
  auto vec = getRandVec(10, -100., 100.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, radix_sort_correct) {
  auto vec = getRandVec(100, -100., 100.);

  auto copy_vec(vec);
  std::sort(copy_vec.begin(), copy_vec.end());

  floatRadixSort(&vec);
  ASSERT_EQ(vec, copy_vec);
}

TEST(kuklin_a_betcher_mergesort, can_merge_2_vec) {
  auto vec = getRandVec(12, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);

  ASSERT_NO_THROW(batcherMerge(copy_vec_first, copy_vec_second));
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_size) {
  auto vec = getRandVec(10, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);

  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);
  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_diff_size) {
  auto vec = getRandVec(13, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);
  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_3_vec) {
  auto vec = getRandVec(20, -100., 100.);
  auto size_copy = vec.size() / 3;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&vec);
  auto tmp_vec = batcherMerge(copy_vec_first, copy_vec_second);
  auto merged_vec = batcherMerge(tmp_vec, copy_vec_third);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_4_vec) {
  auto vec = getRandVec(24, -100., 100.);
  auto size_copy = vec.size() / 4;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy,
                                     vec.begin() + 3 * size_copy);
  std::vector<double> copy_vec_fourth(vec.begin() + 3 * size_copy,
                                     vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&copy_vec_fourth);
  floatRadixSort(&vec);
  auto first_half = batcherMerge(copy_vec_first, copy_vec_second);
  auto second_half = batcherMerge(copy_vec_third, copy_vec_fourth);
  auto merged_vec = batcherMerge(first_half, second_half);

  ASSERT_EQ(merged_vec, vec);
}

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
\end{lstlisting}

\textbf{OpenMP version}
\par batcher\_mergesort.h
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#ifndef MODULES_TASK_1_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
#define MODULES_TASK_1_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_

#include <vector>

using vector_d = std::vector<double>;

std::vector<double> getRandVec(size_t vec_size, double lower_bound,
                               double upper_bound);
std::vector<vector_d> genDigitCounters(vector_d* source_vec, size_t elem_num);
void radixPass(vector_d* source_vec, const std::vector<vector_d>& digitCounters);
void floatRadixSort(vector_d* source_vec);
void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec);
void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec);
void batcherComparator(vector_d* res_vec);
vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec);

#endif  // MODULES_TASK_1_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
\end{lstlisting}
\par batcher\_mergesort.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include "../../../modules/task_2/kuklin_a_batcher_mergesort/batcher_mergesort.h"
#include <omp.h>
#include <algorithm>
#include <vector>
#include <random>

using vector_d = std::vector<double>;
constexpr size_t bv = 256;

vector_d getRandVec(size_t vec_size, double lower_bound, double upper_bound) {
  vector_d vec(vec_size);
  std::uniform_real_distribution<double> distribution(lower_bound, upper_bound);
  std::random_device device;
  std::mt19937 rnd(device());

  for (size_t i = 0; i < vec_size; ++i) vec[i] = distribution(rnd);

  return vec;
}

std::vector<vector_d> genDigitCounters(vector_d* source_vec, size_t elem_num) {
  std::vector<vector_d> digitCounters(256);
  int index_sv = 0;
  int curr_byte = 0;

  for (size_t byte_num = 0; byte_num < sizeof(double); ++byte_num) {
    for (size_t elem_ind = 0; elem_ind < elem_num; ++elem_ind) {
      curr_byte = static_cast<int>(
          *((unsigned char*)&(*source_vec)[elem_ind] + byte_num));
      digitCounters[curr_byte].push_back((*source_vec)[elem_ind]);
    }

    size_t count_size = 0;
    for (size_t i = 0; i < bv; ++i) {
      if (!digitCounters.empty()) {
        count_size = digitCounters[i].size();
        for (size_t j = 0; j < count_size; ++j) {
          (*source_vec)[index_sv++] = digitCounters[i][j];
        }
        digitCounters[i].clear();
      }
    }
    index_sv = 0;
  }

  return digitCounters;
}

void radixPass(vector_d* source_vec, const std::vector<vector_d>& digitCounters) {
  size_t index_v = 0;
  size_t count_size = 0;

  for (size_t i = bv - 1; i >= bv / 2; --i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t k = count_size - 1; k >= 1; --k) {
        (*source_vec)[index_v++] = digitCounters[i][k];
      }
      (*source_vec)[index_v++] = digitCounters[i][0];
    }
  }

  for (size_t i = 0; i < bv / 2; ++i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t j = 0; j < count_size; ++j) {
        (*source_vec)[index_v++] = digitCounters[i][j];
      }
    }
  }
}

void floatRadixSort(vector_d* source_vec) {
  size_t elem_num = source_vec->size();

  auto digitCounters = genDigitCounters(source_vec, elem_num);

  int count_index = 0;
  for (size_t i = 0; i < elem_num; ++i) {
    count_index = static_cast<int>(*((unsigned char*)&(*source_vec)[i] + 7));
    digitCounters[count_index].push_back((*source_vec)[i]);
  }

  radixPass(source_vec, digitCounters);
}

void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec) {
  size_t index_a = 0;
  size_t index_b = 0;
  size_t i = 0;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }
}

void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec) {
  size_t index_a = 1;
  size_t index_b = 1;
  size_t i = 1;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }

  if (first_size % 2 == 1 && second_size % 2 == 1) {
    (*res_vec)[first_size + second_size - 1] =
        std::max(first_vec[first_size - 1], second_vec[second_size - 1]);
  }
}

void batcherComparator(vector_d* res_vec) {
  auto res_size = res_vec->size();

  for (size_t i = 1; i < res_size; ++i) {
    if ((*res_vec)[i] < (*res_vec)[i - 1])
      std::swap((*res_vec)[i], (*res_vec)[i - 1]);
  }
}

vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec) {
  auto first_size = first_vec.size();
  auto second_size = second_vec.size();
  vector_d res_vec(first_size + second_size);

  evenSplitter(&res_vec, first_vec, second_vec);
  oddSplitter(&res_vec, first_vec, second_vec);
  batcherComparator(&res_vec);

  return res_vec;
}

void floatRadixSortParallel(vector_d* source_vec) {
  auto threadNum = omp_get_num_procs();
  std::vector<vector_d> vec_segments(threadNum);

  int segVecNum = source_vec->size() / threadNum;

#pragma omp parallel num_threads(threadNum)
  {
    auto currNumThread = omp_get_thread_num();

    vec_segments[currNumThread] = {
        source_vec->begin() + currNumThread * segVecNum,
        source_vec->begin() + (currNumThread + 1) * segVecNum};

    if (currNumThread == threadNum - 1)
      vec_segments[currNumThread] = {
          source_vec->begin() + currNumThread * segVecNum, source_vec->end()};

    floatRadixSort(&vec_segments[currNumThread]);
  }

  int totalNum = threadNum;
  int mergeCount = threadNum >> 1;

  while (mergeCount) {
    for (int i = 0; i < mergeCount; ++i) {
      vec_segments[i] =
          batcherMerge(vec_segments[i], vec_segments[totalNum - 1 - i]);
    }
    totalNum -= mergeCount;
    mergeCount = totalNum >> 1;
  }

  *source_vec = vec_segments[0];
}
\end{lstlisting}
\par main.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include <gtest/gtest.h>
#include <omp.h>
#include "./batcher_mergesort.h"

TEST(kuklin_a_betcher_mergesort, genRandVec) {
  ASSERT_NO_THROW(getRandVec(10, -100., 100.));
}

TEST(kuklin_a_betcher_mergesort, can_sort_positive_nubm) {
  auto vec = getRandVec(10, 10., 30.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_negative_nubm) {
  auto vec = getRandVec(10, -30., -20.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_rand_nubm) {
  auto vec = getRandVec(10, -100., 100.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, radix_sort_correct) {
  auto vec = getRandVec(100, -100., 100.);

  auto copy_vec(vec);
  std::sort(copy_vec.begin(), copy_vec.end());

  floatRadixSort(&vec);
  ASSERT_EQ(vec, copy_vec);
}

TEST(kuklin_a_betcher_mergesort, can_merge_2_vec) {
  auto vec = getRandVec(12, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);

  ASSERT_NO_THROW(batcherMerge(copy_vec_first, copy_vec_second));
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_size) {
  auto vec = getRandVec(10, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);

  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);
  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_diff_size) {
  auto vec = getRandVec(13, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);
  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_3_vec) {
  auto vec = getRandVec(20, -100., 100.);
  auto size_copy = vec.size() / 3;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&vec);
  auto tmp_vec = batcherMerge(copy_vec_first, copy_vec_second);
  auto merged_vec = batcherMerge(tmp_vec, copy_vec_third);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_4_vec) {
  auto vec = getRandVec(24, -100., 100.);
  auto size_copy = vec.size() / 4;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy,
                                     vec.begin() + 3 * size_copy);
  std::vector<double> copy_vec_fourth(vec.begin() + 3 * size_copy,
                                     vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&copy_vec_fourth);
  floatRadixSort(&vec);
  auto first_half = batcherMerge(copy_vec_first, copy_vec_second);
  auto second_half = batcherMerge(copy_vec_third, copy_vec_fourth);
  auto merged_vec = batcherMerge(first_half, second_half);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort) {
  vector_d vec = {3.1, 7.2, -5.1,   -6.56, -1.345, 10.567,
                  3.5, 2.2, -14.46, -10.,  -11.5,  21.43};

  ASSERT_NO_THROW(floatRadixSortParallel(&vec));
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v1) {
  vector_d seq_vec = {4.1, 3.2, -1.1,   -2.56, -41.345, 30.567,
                      5.5, 6.2, -44.46, -70.5, -31.5,   61.43};
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v2) {
  vector_d seq_vec = {6.1,  7.2, -3.1,   -8.56, -17.345, 25.567,
                      53.5, 4.2, -14.46, -60.5, -24.5,   28.43};
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v3) {
  vector_d seq_vec = {1.1,  0.2,  -5.1,  -68.56, -47.345, 5.567,
                      63.5, 24.2, -4.46, -67.5,  -22.5,   23.43};
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_faster_sequence) {
  auto seq_vec = getRandVec(100000, -100., 100.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
\end{lstlisting}

\textbf{TBB version}
\par batcher\_mergesort.h
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#ifndef MODULES_TASK_3_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
#define MODULES_TASK_3_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_

#include <vector>

using vector_d = std::vector<double>;

std::vector<double> getRandVec(size_t vec_size, double lower_bound,
                               double upper_bound);
void genDigitCounters(vector_d* source_vec, size_t elem_num);
void radixPass(vector_d* source_vec,
               const std::vector<vector_d>& digitCounters);
void floatRadixSort(vector_d* source_vec);
void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec);
void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec);
void batcherComparator(vector_d* res_vec);
vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec);
void floatRadixSortParallel(vector_d* source_vec);

#endif  // MODULES_TASK_3_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
\end{lstlisting}
\par batcher\_mergesort.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include "../../../modules/task_3/kuklin_a_batcher_mergesort/batcher_mergesort.h"
#include <tbb/tbb.h>
#include <algorithm>
#include <vector>
#include <random>

using vector_d = std::vector<double>;
constexpr size_t bv = 256;

vector_d getRandVec(size_t vec_size, double lower_bound, double upper_bound) {
  vector_d vec(vec_size);
  std::uniform_real_distribution<double> distribution(lower_bound, upper_bound);
  std::random_device device;
  std::mt19937 rnd(device());

  for (size_t i = 0; i < vec_size; ++i) vec[i] = distribution(rnd);

  return vec;
}

void genDigitCounters(vector_d* source_vec, size_t elem_num) {
  std::vector<vector_d> digitCounters(bv);
  int index_sv = 0;
  int curr_byte = 0;

  size_t byte_num = 0;

  for (int i = 0; i < 256; ++i) {
    digitCounters[i].reserve(source_vec->size() / 8);
  }

  for (; byte_num < sizeof(double) - 1; ++byte_num) {
    for (size_t elem_ind = 0; elem_ind < elem_num; ++elem_ind) {
      curr_byte = static_cast<int>(
          *(reinterpret_cast<unsigned char*>(source_vec->data() + elem_ind) +
            byte_num));
      digitCounters[curr_byte].push_back((*source_vec)[elem_ind]);
    }
    size_t count_size = 0;
    for (size_t i = 0; i < bv; ++i) {
      if (!digitCounters[i].empty()) {
        count_size = digitCounters[i].size();
        for (size_t j = 0; j < count_size; ++j) {
          (*source_vec)[index_sv++] = digitCounters[i][j];
        }
        digitCounters[i].clear();
      }
    }
    index_sv = 0;
  }

  for (size_t elem_ind = 0; elem_ind < elem_num; ++elem_ind) {
    curr_byte = static_cast<int>(
        *(reinterpret_cast<unsigned char*>(source_vec->data() + elem_ind) +
          byte_num));
    digitCounters[curr_byte].push_back((*source_vec)[elem_ind]);
  }
  size_t count_size = 0;
  for (size_t i = bv - 1; i >= bv / 2; --i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t k = count_size - 1; k >= 1; --k) {
        (*source_vec)[index_sv++] = digitCounters[i][k];
      }
      (*source_vec)[index_sv++] = digitCounters[i][0];
    }
  }
  for (size_t i = 0; i < bv / 2; ++i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t j = 0; j < count_size; ++j) {
        (*source_vec)[index_sv++] = digitCounters[i][j];
      }
    }
  }
}

void radixPass(vector_d* source_vec,
               const std::vector<vector_d>& digitCounters) {
  size_t index_v = 0;
  size_t count_size = 0;

  for (size_t i = bv - 1; i >= bv / 2; --i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t k = count_size - 1; k >= 1; --k) {
        (*source_vec)[index_v++] = digitCounters[i][k];
      }
      (*source_vec)[index_v++] = digitCounters[i][0];
    }
  }

  for (size_t i = 0; i < bv / 2; ++i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t j = 0; j < count_size; ++j) {
        (*source_vec)[index_v++] = digitCounters[i][j];
      }
    }
  }
}

void floatRadixSort(vector_d* source_vec) {
  size_t elem_num = source_vec->size();

  genDigitCounters(source_vec, elem_num);
}

void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec) {
  size_t index_a = 0;
  size_t index_b = 0;
  size_t i = 0;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }
}

void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec) {
  size_t index_a = 1;
  size_t index_b = 1;
  size_t i = 1;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }

  if (first_size % 2 == 1 && second_size % 2 == 1) {
    (*res_vec)[first_size + second_size - 1] =
        (std::max)(first_vec[first_size - 1], second_vec[second_size - 1]);
  }
}

void batcherComparator(vector_d* res_vec) {
  auto res_size = res_vec->size();

  for (size_t i = 1; i < res_size; ++i) {
    if ((*res_vec)[i] < (*res_vec)[i - 1])
      std::swap((*res_vec)[i], (*res_vec)[i - 1]);
  }
}

vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec) {
  auto first_size = first_vec.size();
  auto second_size = second_vec.size();
  vector_d res_vec(first_size + second_size);

  tbb::task_group gr;
  gr.run([&]() { evenSplitter(&res_vec, first_vec, second_vec); });
  gr.run([&]() { oddSplitter(&res_vec, first_vec, second_vec); });
  gr.wait();

  batcherComparator(&res_vec);

  return res_vec;
}

void floatRadixSortParallel(vector_d* source_vec) {
  auto numThread = tbb::task_scheduler_init::default_num_threads();
  auto sizeVec = source_vec->size() / numThread;
  std::vector<vector_d> vec_seg(numThread);

  for (int i = 0; i < numThread - 1; ++i) {
    vec_seg[i].resize(sizeVec);
    std::copy(source_vec->begin() + i * sizeVec,
                           source_vec->begin() + (i + 1) * sizeVec, vec_seg[i].begin());
  }
  int remainSize = source_vec->size() % numThread + sizeVec;
  vec_seg[numThread - 1].resize(remainSize);
  std::copy(source_vec->end() - remainSize, source_vec->end(),
            vec_seg[numThread - 1].begin());

  tbb::parallel_for(tbb::blocked_range<int>(0, numThread),
                    [&](tbb::blocked_range<int> range) {
                      for (auto i = range.begin(); i < range.end(); ++i) {
                        floatRadixSort(&vec_seg[i]);
                      }
                    });

  int totalNum = vec_seg.size();
  int mergeCount = totalNum >> 1;

  while (mergeCount) {
    tbb::parallel_for(tbb::blocked_range<int>(0, mergeCount),
                      [&](tbb::blocked_range<int> range) {
                        for (auto i = range.begin(); i < range.end(); ++i) {
                          vec_seg[i] =
                              batcherMerge(vec_seg[i],
                                           vec_seg[totalNum - 1 - i]);
                        }
                      });
    totalNum -= mergeCount;
    mergeCount = totalNum >> 1;
  }

  *source_vec = vec_seg[0];
}
\end{lstlisting}
\par main.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include <gtest/gtest.h>
#include <tbb/tbb.h>
#include <iostream>
#include "./batcher_mergesort.h"

TEST(kuklin_a_betcher_mergesort, genRandVec) {
  ASSERT_NO_THROW(getRandVec(10, -100., 100.));
}

TEST(kuklin_a_betcher_mergesort, can_sort_positive_nubm) {
  auto vec = getRandVec(10, 10., 30.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_negative_nubm) {
  auto vec = getRandVec(10, -30., -20.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_rand_nubm) {
  auto vec = getRandVec(10, -100., 100.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, radix_sort_correct) {
  auto vec = getRandVec(100, -100., 100.);

  auto copy_vec(vec);
  std::sort(copy_vec.begin(), copy_vec.end());

  floatRadixSort(&vec);
  ASSERT_EQ(vec, copy_vec);
}

TEST(kuklin_a_betcher_mergesort, can_merge_2_vec) {
  auto vec = getRandVec(12, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);

  ASSERT_NO_THROW(batcherMerge(copy_vec_first, copy_vec_second));
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_size) {
  auto vec = getRandVec(10, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);

  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);
  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_diff_size) {
  auto vec = getRandVec(13, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);
  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_3_vec) {
  auto vec = getRandVec(20, -100., 100.);
  auto size_copy = vec.size() / 3;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&vec);
  auto tmp_vec = batcherMerge(copy_vec_first, copy_vec_second);
  auto merged_vec = batcherMerge(tmp_vec, copy_vec_third);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_4_vec) {
  auto vec = getRandVec(24, -100., 100.);
  auto size_copy = vec.size() / 4;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy,
                                     vec.begin() + 3 * size_copy);
  std::vector<double> copy_vec_fourth(vec.begin() + 3 * size_copy,
                                     vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&copy_vec_fourth);
  floatRadixSort(&vec);
  auto first_half = batcherMerge(copy_vec_first, copy_vec_second);
  auto second_half = batcherMerge(copy_vec_third, copy_vec_fourth);
  auto merged_vec = batcherMerge(first_half, second_half);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort) {
  auto vec = getRandVec(12, -100., 100.);

  ASSERT_NO_THROW(floatRadixSortParallel(&vec));
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v1) {
  auto seq_vec = getRandVec(17, -150., 150.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v2) {
  auto seq_vec = getRandVec(21, -200., 200.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v3) {
  auto seq_vec = getRandVec(39, -240., 240.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_faster_sequence) {
  auto seq_vec = getRandVec(100, -100., 100.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
\end{lstlisting}

\textbf{std::thread version}
\par batcher\_mergesort.h
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#ifndef MODULES_TASK_4_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
#define MODULES_TASK_4_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_

#include <vector>

using vector_d = std::vector<double>;

std::vector<double> getRandVec(size_t vec_size, double lower_bound,
                               double upper_bound);
void genDigitCounters(vector_d* source_vec, size_t elem_num);
void radixPass(vector_d* source_vec,
               const std::vector<vector_d>& digitCounters);
void floatRadixSort(vector_d* source_vec);
void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec);
void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec);
void batcherComparator(vector_d* res_vec);
vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec);
void floatRadixSortParallel(vector_d* source_vec);

#endif  // MODULES_TASK_4_KUKLIN_A_BATCHER_MERGESORT_BATCHER_MERGESORT_H_
\end{lstlisting}
\par batcher\_mergesort.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include "../../../modules/task_4/kuklin_a_batcher_mergesort/batcher_mergesort.h"
#include <algorithm>
#include <vector>
#include <random>
#include <thread> // NOLINT

using vector_d = std::vector<double>;
constexpr size_t bv = 256;

vector_d getRandVec(size_t vec_size, double lower_bound, double upper_bound) {
  vector_d vec(vec_size);
  std::uniform_real_distribution<double> distribution(lower_bound, upper_bound);
  std::random_device device;
  std::mt19937 rnd(device());

  for (size_t i = 0; i < vec_size; ++i) vec[i] = distribution(rnd);

  return vec;
}

void genDigitCounters(vector_d* source_vec, size_t elem_num) {
  std::vector<vector_d> digitCounters(bv);
  int index_sv = 0;
  int curr_byte = 0;

  size_t byte_num = 0;

  for (int i = 0; i < 256; ++i) {
    digitCounters[i].reserve(source_vec->size() / 8);
  }

  for (; byte_num < sizeof(double) - 1; ++byte_num) {
    for (size_t elem_ind = 0; elem_ind < elem_num; ++elem_ind) {
      curr_byte = static_cast<int>(
          *(reinterpret_cast<unsigned char*>(source_vec->data() + elem_ind) +
            byte_num));
      digitCounters[curr_byte].push_back((*source_vec)[elem_ind]);
    }
    size_t count_size = 0;
    for (size_t i = 0; i < bv; ++i) {
      if (!digitCounters[i].empty()) {
        count_size = digitCounters[i].size();
        for (size_t j = 0; j < count_size; ++j) {
          (*source_vec)[index_sv++] = digitCounters[i][j];
        }
        digitCounters[i].clear();
      }
    }
    index_sv = 0;
  }

  for (size_t elem_ind = 0; elem_ind < elem_num; ++elem_ind) {
    curr_byte = static_cast<int>(
        *(reinterpret_cast<unsigned char*>(source_vec->data() + elem_ind) +
          byte_num));
    digitCounters[curr_byte].push_back((*source_vec)[elem_ind]);
  }
  size_t count_size = 0;
  for (size_t i = bv - 1; i >= bv / 2; --i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t k = count_size - 1; k >= 1; --k) {
        (*source_vec)[index_sv++] = digitCounters[i][k];
      }
      (*source_vec)[index_sv++] = digitCounters[i][0];
    }
  }
  for (size_t i = 0; i < bv / 2; ++i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t j = 0; j < count_size; ++j) {
        (*source_vec)[index_sv++] = digitCounters[i][j];
      }
    }
  }
}

void radixPass(vector_d* source_vec,
               const std::vector<vector_d>& digitCounters) {
  size_t index_v = 0;
  size_t count_size = 0;

  for (size_t i = bv - 1; i >= bv / 2; --i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t k = count_size - 1; k >= 1; --k) {
        (*source_vec)[index_v++] = digitCounters[i][k];
      }
      (*source_vec)[index_v++] = digitCounters[i][0];
    }
  }

  for (size_t i = 0; i < bv / 2; ++i) {
    if (!digitCounters[i].empty()) {
      count_size = digitCounters[i].size();
      for (size_t j = 0; j < count_size; ++j) {
        (*source_vec)[index_v++] = digitCounters[i][j];
      }
    }
  }
}

void floatRadixSort(vector_d* source_vec) {
  size_t elem_num = source_vec->size();

  genDigitCounters(source_vec, elem_num);
}

void evenSplitter(vector_d* res_vec, const vector_d& first_vec,
                  const vector_d& second_vec) {
  size_t index_a = 0;
  size_t index_b = 0;
  size_t i = 0;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }
}

void oddSplitter(vector_d* res_vec, const vector_d& first_vec,
                 const vector_d& second_vec) {
  size_t index_a = 1;
  size_t index_b = 1;
  size_t i = 1;

  auto first_size = first_vec.size();
  auto second_size = second_vec.size();

  while ((index_a < first_size) && (index_b < second_size)) {
    if (first_vec[index_a] <= second_vec[index_b]) {
      (*res_vec)[i] = first_vec[index_a];
      index_a += 2;
    } else {
      (*res_vec)[i] = second_vec[index_b];
      index_b += 2;
    }
    i += 2;
  }

  if (index_a >= first_size) {
    for (size_t j = index_b; j < second_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = second_vec[j];
  } else {
    for (size_t j = index_a; j < first_size && i < first_size + second_size;
         j += 2, i += 2)
      (*res_vec)[i] = first_vec[j];
  }

  if (first_size % 2 == 1 && second_size % 2 == 1) {
    (*res_vec)[first_size + second_size - 1] =
        (std::max)(first_vec[first_size - 1], second_vec[second_size - 1]);
  }
}

void batcherComparator(vector_d* res_vec) {
  auto res_size = res_vec->size();

  for (size_t i = 1; i < res_size; ++i) {
    if ((*res_vec)[i] < (*res_vec)[i - 1])
      std::swap((*res_vec)[i], (*res_vec)[i - 1]);
  }
}

vector_d batcherMerge(const vector_d& first_vec, const vector_d& second_vec) {
  auto first_size = first_vec.size();
  auto second_size = second_vec.size();
  vector_d res_vec(first_size + second_size);

  evenSplitter(&res_vec, first_vec, second_vec);
  oddSplitter(&res_vec, first_vec, second_vec);
  batcherComparator(&res_vec);

  return res_vec;
}

void floatRadixSortParallel(vector_d* source_vec) {
  auto threadNum = std::thread::hardware_concurrency();
  size_t vecSize = source_vec->size() / threadNum;
  std::vector<vector_d> vec_segments(threadNum);

  for (size_t i = 0; i < threadNum - 1; ++i) {
    vec_segments[i].resize(vecSize);
    std::copy(source_vec->begin() + i * vecSize,
              source_vec->begin() + (i + 1) * vecSize, vec_segments[i].begin());
  }

  size_t remainSize = source_vec->size() % threadNum + vecSize;
  vec_segments[threadNum - 1].resize(remainSize);
  std::copy(source_vec->end() - remainSize, source_vec->end(), vec_segments[threadNum - 1].begin());

  std::vector<std::thread> thread_vec(threadNum);
  for (size_t i = 0; i < threadNum; ++i) {
    thread_vec[i] = std::thread{floatRadixSort, &vec_segments[i]};
    thread_vec[i].join();
  }

  int totalNum = vec_segments.size();
  int mergeCount = totalNum >> 1;

  while (mergeCount) {
    for (int i = 0; i < mergeCount; ++i) {
      vec_segments[i] =
          batcherMerge(vec_segments[i], vec_segments[totalNum - 1 - i]);
    }
    totalNum -= mergeCount;
    mergeCount = totalNum >> 1;
  }

  *source_vec = vec_segments[0];
}
\end{lstlisting}
\par main.cpp
\begin{lstlisting}
// Copyright 2022 Kuklin Andrey
#include <gtest/gtest.h>
#include "./batcher_mergesort.h"

TEST(kuklin_a_betcher_mergesort, genRandVec) {
  ASSERT_NO_THROW(getRandVec(10, -100., 100.));
}

TEST(kuklin_a_betcher_mergesort, can_sort_positive_numb) {
  auto vec = getRandVec(10, 10., 30.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_negative_numb) {
  auto vec = getRandVec(10, -30., -20.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, can_sort_rand_numb) {
  auto vec = getRandVec(10, -100., 100.);

  ASSERT_NO_THROW(floatRadixSort(&vec));
}

TEST(kuklin_a_betcher_mergesort, radix_sort_correct) {
  auto vec = getRandVec(100, -100., 100.);

  auto copy_vec(vec);
  std::sort(copy_vec.begin(), copy_vec.end());

  floatRadixSort(&vec);
  ASSERT_EQ(vec, copy_vec);
}

TEST(kuklin_a_betcher_mergesort, can_merge_2_vec) {
  auto vec = getRandVec(12, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);

  ASSERT_NO_THROW(batcherMerge(copy_vec_first, copy_vec_second));
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_size) {
  auto vec = getRandVec(10, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);

  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);
  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_vec_eq_diff_size) {
  auto vec = getRandVec(13, -100., 100.);
  auto size_copy = vec.size() / 2;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&vec);
  auto merged_vec = batcherMerge(copy_vec_first, copy_vec_second);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_3_vec) {
  auto vec = getRandVec(20, -100., 100.);
  auto size_copy = vec.size() / 3;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy, vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&vec);
  auto tmp_vec = batcherMerge(copy_vec_first, copy_vec_second);
  auto merged_vec = batcherMerge(tmp_vec, copy_vec_third);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, correct_merge_4_vec) {
  auto vec = getRandVec(24, -100., 100.);
  auto size_copy = vec.size() / 4;
  std::vector<double> copy_vec_first(vec.begin(), vec.begin() + size_copy);
  std::vector<double> copy_vec_second(vec.begin() + size_copy,
                                      vec.begin() + 2 * size_copy);
  std::vector<double> copy_vec_third(vec.begin() + 2 * size_copy,
                                     vec.begin() + 3 * size_copy);
  std::vector<double> copy_vec_fourth(vec.begin() + 3 * size_copy,
                                     vec.end());

  floatRadixSort(&copy_vec_first);
  floatRadixSort(&copy_vec_second);
  floatRadixSort(&copy_vec_third);
  floatRadixSort(&copy_vec_fourth);
  floatRadixSort(&vec);
  auto first_half = batcherMerge(copy_vec_first, copy_vec_second);
  auto second_half = batcherMerge(copy_vec_third, copy_vec_fourth);
  auto merged_vec = batcherMerge(first_half, second_half);

  ASSERT_EQ(merged_vec, vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort) {
  auto vec = getRandVec(12, -100., 100.);

  ASSERT_NO_THROW(floatRadixSortParallel(&vec));
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v1) {
  auto seq_vec = getRandVec(17, -150., 150.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v2) {
  auto seq_vec = getRandVec(21, -200., 200.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_eq_sequence_v3) {
  auto seq_vec = getRandVec(39, -240., 240.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

TEST(kuklin_a_betcher_mergesort, parallel_sort_faster_sequence) {
  auto seq_vec = getRandVec(100, -100., 100.);
  vector_d par_vec = seq_vec;

  floatRadixSort(&seq_vec);
  floatRadixSortParallel(&par_vec);

  ASSERT_EQ(seq_vec, par_vec);
}

int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
\end{lstlisting}

\end{document}